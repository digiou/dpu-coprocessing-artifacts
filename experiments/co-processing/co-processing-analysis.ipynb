{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e59c3ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: {'static': 31.97834088959665, 'reconfiguration': 30.438697857590885},\n",
       " 70: {'static': 77.4070359864457, 'reconfiguration': 71.70595817260433},\n",
       " 90: {'static': 233.43514889216965, 'reconfiguration': 123.48639410822146},\n",
       " 80: {'static': 114.71725544867532, 'reconfiguration': 95.15381134344318},\n",
       " 40: {'static': 41.06306195985683, 'reconfiguration': 38.955311952611844},\n",
       " 60: {'static': 59.25174485264477, 'reconfiguration': 55.251000187669625},\n",
       " 50: {'static': 48.84624431910509, 'reconfiguration': 46.067005010893524},\n",
       " 0: {'static': 25.51804771002575, 'reconfiguration': 25.51804771002575},\n",
       " 10: {'static': 28.31210745602425, 'reconfiguration': 27.778281838499254},\n",
       " 30: {'static': 36.229392386871496, 'reconfiguration': 34.34155118948264},\n",
       " 100: {'static': 2754.2790873734593, 'reconfiguration': 141.37024998243638}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compress analysis\n",
    "import glob, json, os, re, csv\n",
    "\n",
    "# results dir\n",
    "dir = \"results/compress\"\n",
    "\n",
    "# devices\n",
    "devices = [\"bf2\"]\n",
    "\n",
    "# Dictionary to store results indexed by (i, j)\n",
    "results = {device: {} for device in devices}\n",
    "reconfiguration_results = {device: {} for device in devices}\n",
    "\n",
    "# averages for plotting\n",
    "averaged_results = {device: {} for device in devices}\n",
    "\n",
    "# Pattern to match results\n",
    "cpu_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-cpu-compress\\.json\")\n",
    "doca_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-doca-compress\\.json\")\n",
    "\n",
    "# Load all matching JSON files\n",
    "for device in devices:\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-*-*-*-cpu-compress.json\"):\n",
    "        match = cpu_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    "\n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                    reconfiguration_results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "\n",
    "            if 0 < i < 100:\n",
    "                with open(f\"{dir}/{device}/results-{i}-{j}-{filename}-doca-compress.json\", \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "                reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "            elif i == 100:\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "    \n",
    "    # no cpu file, only dpu\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-0-100-*-doca-compress.json\"):\n",
    "        match = doca_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    " \n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                reconfiguration_results[device][key] = []\n",
    "\n",
    "            reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "            reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "            reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "\n",
    "    averaged_results[device] = {key: {\"static\": 0, \"reconfiguration\": 0} for key in results[device].keys()}\n",
    "    for key in results[device].keys():\n",
    "        key_avg = sum(results[device][key]) / len(results[device][key])\n",
    "        averaged_results[device][key][\"static\"] = key_avg\n",
    "        reconfiguration_key_avg = sum(reconfiguration_results[device][key]) / len(reconfiguration_results[device][key])\n",
    "        averaged_results[device][key][\"reconfiguration\"] = reconfiguration_key_avg\n",
    "\n",
    "display(averaged_results[\"bf2\"])\n",
    "\n",
    "# Write to CSV\n",
    "with open(f\"../../tex/figures/za-evaluation/coprocessing-compress-deflate.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"sharing_percentage\", \"static\", \"reconfiguration\"])\n",
    "\n",
    "    # Write rows\n",
    "    sorted_keys = sorted(averaged_results[\"bf2\"].keys())\n",
    "    for key in sorted_keys: # only bf2 has this item\n",
    "        writer.writerow([key, averaged_results[\"bf2\"][key][\"static\"], averaged_results[\"bf2\"][key][\"reconfiguration\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f06d917f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{40: {'static': 323.40756766274814, 'reconfiguration': 142.8504715684955},\n",
       " 20: {'static': 232.62281548665692, 'reconfiguration': 128.25695895374042},\n",
       " 70: {'static': 444.6406759400579, 'reconfiguration': 146.5376473025934},\n",
       " 90: {'static': 1046.2958408293343, 'reconfiguration': 145.94624957883494},\n",
       " 60: {'static': 423.46977850475787, 'reconfiguration': 145.5138356034847},\n",
       " 50: {'static': 353.5021788617539, 'reconfiguration': 148.0697296330436},\n",
       " 10: {'static': 214.32047108176798, 'reconfiguration': 123.31823058428309},\n",
       " 80: {'static': 610.4107844513184, 'reconfiguration': 144.88852856666875},\n",
       " 0: {'static': 219.52897002752616, 'reconfiguration': 219.52897002752616},\n",
       " 30: {'static': 266.62112481664013, 'reconfiguration': 134.72678541970194},\n",
       " 100: {'static': 3201.554378106742, 'reconfiguration': 145.21167536260648}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decompress deflate analysis\n",
    "import glob, json, os, re, csv\n",
    "\n",
    "# results dir\n",
    "dir = \"results/decompress-deflate\"\n",
    "\n",
    "# devices\n",
    "devices = [\"bf2\"]\n",
    "\n",
    "# Dictionary to store results indexed by (i, j)\n",
    "results = {device: {} for device in devices}\n",
    "reconfiguration_results = {device: {} for device in devices}\n",
    "\n",
    "# averages for plotting\n",
    "averaged_results = {device: {} for device in devices}\n",
    "\n",
    "# Pattern to match results\n",
    "cpu_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-cpu-decompress-deflate\\.json\")\n",
    "doca_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-doca-decompress-deflate\\.json\")\n",
    "\n",
    "# Load all matching JSON files\n",
    "for device in devices:\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-*-*-*-cpu-decompress-deflate.json\"):\n",
    "        match = cpu_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    "\n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                    reconfiguration_results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "\n",
    "            if 0 < i < 100:\n",
    "                with open(f\"{dir}/{device}/results-{i}-{j}-{filename}-doca-decompress-deflate.json\", \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "                reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "            elif i == 100:\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "    \n",
    "    # no cpu file, only dpu\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-0-100-*-doca-decompress-deflate.json\"):\n",
    "        match = doca_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    " \n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                reconfiguration_results[device][key] = []\n",
    "\n",
    "            reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "            reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "            reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "\n",
    "    averaged_results[device] = {key: {\"static\": 0, \"reconfiguration\": 0} for key in results[device].keys()}\n",
    "    for key in results[device].keys():\n",
    "        key_avg = sum(results[device][key]) / len(results[device][key])\n",
    "        averaged_results[device][key][\"static\"] = key_avg\n",
    "        reconfiguration_key_avg = sum(reconfiguration_results[device][key]) / len(reconfiguration_results[device][key])\n",
    "        averaged_results[device][key][\"reconfiguration\"] = reconfiguration_key_avg\n",
    "\n",
    "display(averaged_results[\"bf2\"])\n",
    "\n",
    "# Write to CSV\n",
    "with open(f\"../../tex/figures/za-evaluation/coprocessing-decompress-deflate.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"sharing_percentage\", \"static\", \"reconfiguration\"])\n",
    "\n",
    "    # Write rows\n",
    "    sorted_keys = sorted(averaged_results[\"bf2\"].keys())\n",
    "    for key in sorted_keys: # only bf2 has this item\n",
    "        writer.writerow([key, averaged_results[\"bf2\"][key][\"static\"], averaged_results[\"bf2\"][key][\"reconfiguration\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66209dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{40: {'static': 9680.359366689136, 'reconfiguration': 164.50570772535045},\n",
       " 30: {'static': 8526.014723419525, 'reconfiguration': 164.52023381052172},\n",
       " 10: {'static': 7349.998844811561, 'reconfiguration': 164.02470324891502},\n",
       " 20: {'static': 8055.9290149362, 'reconfiguration': 164.53369447794847},\n",
       " 50: {'static': 11173.193967907226, 'reconfiguration': 163.09291234801472},\n",
       " 90: {'static': 26920.13681904299, 'reconfiguration': 162.05004642094357},\n",
       " 80: {'static': 20043.318426500908, 'reconfiguration': 162.87624556857142},\n",
       " 70: {'static': 15111.081790101607, 'reconfiguration': 163.8558019412535},\n",
       " 60: {'static': 12909.527052781736, 'reconfiguration': 163.5658564003557},\n",
       " 100: {'static': 26565.192144620378, 'reconfiguration': 163.57776057104434}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decompress LZ4 analysis\n",
    "import glob, json, os, re, csv\n",
    "\n",
    "# results dir\n",
    "dir = \"results/decompress-lz4\"\n",
    "\n",
    "# devices\n",
    "devices = [\"bf3\"]\n",
    "\n",
    "# Dictionary to store results indexed by (i, j)\n",
    "results = {device: {} for device in devices}\n",
    "reconfiguration_results = {device: {} for device in devices}\n",
    "\n",
    "# averages for plotting\n",
    "averaged_results = {device: {} for device in devices}\n",
    "\n",
    "# Pattern to match results\n",
    "cpu_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-cpu-decompress-lz4\\.json\")\n",
    "doca_pattern = re.compile(r\"results-(\\d+)-(\\d+)-(.+)-doca-decompress-lz4\\.json\")\n",
    "\n",
    "# Load all matching JSON files\n",
    "for device in devices:\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-*-*-*-cpu-decompress-lz4.json\"):\n",
    "        match = cpu_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    "\n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                    reconfiguration_results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "\n",
    "            if 0 < i < 100:\n",
    "                with open(f\"{dir}/{device}/results-{i}-{j}-{filename}-doca-decompress-lz4.json\", \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "                reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "            elif i == 100:\n",
    "                reconfiguration_results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "    \n",
    "    # no cpu file, only dpu\n",
    "    for file in glob.glob(f\"{dir}/{device}/results-0-100-*-doca-decompress-lz4.json\"):\n",
    "        match = doca_pattern.match(os.path.basename(file))\n",
    "        if match:\n",
    "            i, j, filename = match.groups()\n",
    "            i, j = int(i), int(j)  # Convert i, j to integers\n",
    " \n",
    "            # Read JSON content\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            with open(f\"{dir}/{device}/results-{i}-{j}-{filename}.size\", 'r') as ssize:\n",
    "                full_file_size = int(ssize.readline().strip().split()[-1])\n",
    "\n",
    "            # Store in results dictionary, use doca as \"sharing percentage\"\n",
    "            key = j\n",
    "            if key not in results[device]:\n",
    "                results[device][key] = []\n",
    "\n",
    "            joined_runtime_seconds = float(data[\"joined_submission_elapsed\"])\n",
    "            results[device][key].append((full_file_size / 1_048_576) / joined_runtime_seconds)\n",
    "\n",
    "            if key not in reconfiguration_results[device]:\n",
    "                reconfiguration_results[device][key] = []\n",
    "\n",
    "            reconfiguration_runtime_seconds = float(data[\"overall_submission_elapsed\"]) + float(data[\"ctx_stop_elapsed\"])\n",
    "            reconfiguration_runtime_seconds = max(joined_runtime_seconds, reconfiguration_runtime_seconds)\n",
    "            reconfiguration_results[device][key].append((full_file_size / 1_048_576) / reconfiguration_runtime_seconds)\n",
    "\n",
    "    averaged_results[device] = {key: {\"static\": 0, \"reconfiguration\": 0} for key in results[device].keys()}\n",
    "    for key in results[device].keys():\n",
    "        key_avg = sum(results[device][key]) / len(results[device][key])\n",
    "        averaged_results[device][key][\"static\"] = key_avg\n",
    "        reconfiguration_key_avg = sum(reconfiguration_results[device][key]) / len(reconfiguration_results[device][key])\n",
    "        averaged_results[device][key][\"reconfiguration\"] = reconfiguration_key_avg\n",
    "\n",
    "display(averaged_results[\"bf3\"])\n",
    "\n",
    "# Write to CSV\n",
    "with open(f\"../../tex/figures/za-evaluation/coprocessing-decompress-lz4-r.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"sharing_percentage\", \"static\", \"reconfiguration\"])\n",
    "\n",
    "    # Write rows\n",
    "    sorted_keys = sorted(averaged_results[\"bf3\"].keys())\n",
    "    for key in sorted_keys: # only bf3 has this item\n",
    "        writer.writerow([key, averaged_results[\"bf3\"][key][\"static\"], averaged_results[\"bf3\"][key][\"reconfiguration\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
